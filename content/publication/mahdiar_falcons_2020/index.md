---
title: "FALCONS: FAst Learner-grader for CONtorted poses in Sports"

# if the author is from our lab, then you need to match it with the folder name you can find here
# https://github.com/Vision-and-Learning-Lab-UAlberta/home/tree/master/content/authors
# otherwise just write down their full name
authors:
- mahdiarn # in our lab
- Fidel Omar Tito Cruz
- licheng # in our lab

date: "2020-06-19T00:00:00Z"
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: "2020-01-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
# you can have this as multiple types, just use a list like ["1", "3"]
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops
publication_short: CVPRW

abstract: "Isn't it about time to help judges with the challenging task of evaluating athletes' performances in sports with extreme poses? To tackle this problem and inspired by human judges' grading schema, we propose a virtual refereeing network to evaluate the execution of a diving performance. This assessment would be based on visual clues as well as the body joints sequence of the action video. In order to cover the unusual body contortions in such scenarios, we present ExPose: annotated dataset of Extreme Poses. We further introduce a simple yet effective module to assess the difficulty of the performance based on the extracted joints sequence. Finally, the overall score of the performance would be reported as the multiplication of the execution and difficulty scores. The results demonstrate our proposed lightweight network not only achieves state-of-the-art results compared to previous studies in diving but also shows acceptable generalization to other contortive sports."
# Summary. An optional shortened abstract.
# summary: A hierarchical recurrent network structure is developed to simultaneously encodes local contexts of individual frames and global contexts of the sequence.

tags:
- CVPR
- CVPRW

featured: false

links:
url_pdf: http://openaccess.thecvf.com/content_CVPRW_2020/papers/w53/Nekoui_FALCONS_FAst_Learner-Grader_for_CONtorted_Poses_in_Sports_CVPRW_2020_paper.pdf
url_dataset: https://drive.google.com/drive/folders/1HQDMIbbwHWerr8AXfPf08K1cwR-G1z7Y?usp=sharing
url_slides: https://drive.google.com/drive/folders/1i-W8DojbMeEM8ew7Cp67V694n2XMnQtC?usp=sharing

# url_code: https://github.com/BII-wushuang/Lie-Group-Motion-Prediction
# url_poster: 
# url_project: https://coderstellaj.github.io/Hierarchical-Motion-Recurrent-Network-Website/ 
# url_source: 
# url_video: https://www.youtube.com/watch?v=qi33KKUzrVA&feature=emb_title


# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# If you have one, please zip together
image:
  caption: ''
  focal_point: ""
  preview_only: false

---